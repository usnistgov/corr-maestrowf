{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate SEM Image Stats\n",
    "\n",
    "See the [README](./README.md) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import scipy.ndimage\n",
    "import pytesseract\n",
    "import PIL.Image\n",
    "from toolz.curried import map, pipe, compose, get, do, curry, count, pluck, juxt, flip\n",
    "import pandas\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Helper Functions\n",
    "\n",
    "`fcompose` is a helper function that doesn't seem to be in Toolz, but seems to make writing function pipelines much easier, likewise, when working with lists of dictionaries and data frames, `mapdict` and `dfassing` seem useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcompose = lambda *args: compose(*args[::-1])\n",
    "\n",
    "mapdict = lambda **kwargs: map(lambda data: dict(dict((k, f(data)) for k, f in kwargs.items()), **data))\n",
    "\n",
    "## Helper functions\n",
    "@curry\n",
    "def dfassign(df, **kwargs):\n",
    "    return df.assign(**dict(((k, f(df)) for k, f in kwargs.items())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## View the images\n",
    "reshape = lambda arr: arr if len(arr.shape) == 2 else arr[...,0]\n",
    "to_array = lambda image: reshape(numpy.asarray(image.convert(\"L\")))\n",
    "\n",
    "def plt_arrays(arrs):\n",
    "    \"\"\"Plot a set of (n, n) arrays as row column sub plots.\n",
    "    \"\"\"\n",
    "    fig = matplotlib.pyplot.figure(figsize=(7, 7))\n",
    "    N = int(numpy.ceil(numpy.sqrt(len(arrs))))\n",
    "    for i, arr in enumerate(arrs):\n",
    "        ax = fig.add_subplot(N, N, i + 1)\n",
    "        out = ax.imshow(arr, cmap='Greys_r', interpolation='none')\n",
    "        out.axes.get_xaxis().set_visible(False)\n",
    "        out.axes.get_yaxis().set_visible(False)\n",
    "    matplotlib.pyplot.tight_layout()\n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the Metadata\n",
    "\n",
    "Each image has metadata embedded in the image. Here, `pytesseract` is used to extract this data. The images are cropped to split them into two upper and lower sections. The text extraction works better without the microstructure noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract the metadata\n",
    "@curry\n",
    "def crop_image(image, cutoff=960):\n",
    "    \"\"\"Crop the images into the \"upper\" and \"lower\" portions.\n",
    "\n",
    "    Splits the image into the actual image of the microstructure and the embedded metadata.\n",
    "\n",
    "    Args:\n",
    "      image: a PIL image\n",
    "      cutoff: the cutoff height for the upper image\n",
    "\n",
    "    Returns:\n",
    "      {'upper' : upper_image, 'lower': lower_image}\n",
    "    \"\"\"\n",
    "    return dict(\n",
    "               upper=image.crop(box=(0, 0, image.size[0], cutoff)),\n",
    "               lower=image.crop(box=(0, cutoff, image.size[0], image.size[1]))\n",
    "           )\n",
    "\n",
    "def plt_array(arr):\n",
    "    \"\"\"Plot a single 2D array\n",
    "    \"\"\"\n",
    "    ax = matplotlib.pyplot.imshow(arr, cmap='Greys_r', interpolation='none')\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    matplotlib.pyplot.tight_layout\n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata required from the images is the scale of the images. This requires the real scale size given by the number to the right of the scale bar and the size of the scale bar in pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "repair_string = lambda string: float('10' if string == 'mum' else string.replace('pm', ''))\n",
    "\n",
    "scale_pixels = fcompose(\n",
    "    to_array,\n",
    "    lambda data: skimage.measure.label(data, background=0),\n",
    "    skimage.measure.regionprops,\n",
    "    get(1),\n",
    "    lambda data: data.bbox[3] - data.bbox[1],\n",
    ")\n",
    "\n",
    "extract_strings = fcompose(\n",
    "    lambda image: pytesseract.image_to_string(image),\n",
    "    lambda string: string.split(),\n",
    "    get([1, 3, -1]),\n",
    "    lambda data: dict(scale_microns=repair_string(data[0]),\n",
    "                      date=data[1].replace('-', ''),\n",
    "                      time=data[2])\n",
    ")\n",
    "\n",
    "extract_metadata = fcompose(\n",
    "    PIL.Image.open,\n",
    "    crop_image,\n",
    "    get('lower'),\n",
    "    lambda image: dict(scale_pixels=scale_pixels(image), **extract_strings(image))\n",
    ")\n",
    "\n",
    "## Rescale the images\n",
    "extract_image = fcompose(\n",
    "    PIL.Image.open,\n",
    "    crop_image,\n",
    "    get('upper')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescale the Images\n",
    "\n",
    "An array data point needs to have the same representation across all the images. This is done by rescaling the all the images to have the scale of the coarsest sampling. This isn't currently used for any later analysis, but is an intersting use of data analysis and shows how to pass dataframes and dictionaries through the function pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_image(image, rescale_factor):\n",
    "    \"\"\"Scale the image using PIL's thumbnail\n",
    "\n",
    "    thumbnail is an inplace operation so copies are required.\n",
    "\n",
    "    Args:\n",
    "      image: a PIL image\n",
    "      rescale_factor: how much to rescale the image by\n",
    "\n",
    "    Returns:\n",
    "      a new image\n",
    "    \"\"\"\n",
    "    copy_image = image.copy()\n",
    "    copy_image.thumbnail(numpy.array(copy_image.size) * rescale_factor, PIL.Image.ANTIALIAS)\n",
    "    return copy_image\n",
    "\n",
    "get_df = fcompose(\n",
    "    glob.glob,\n",
    "    sorted,\n",
    "    map(\n",
    "        lambda filename: dict(filename=filename,\n",
    "                              **extract_metadata(filename))\n",
    "    ),\n",
    "    list,\n",
    "    pandas.DataFrame,\n",
    "    dfassign(pixel_size=lambda df: df['scale_microns'] / df['scale_pixels']),\n",
    "    dfassign(rescale_factor=lambda df: df['pixel_size'] / max(df['pixel_size'])),\n",
    ")\n",
    "\n",
    "scaled_images = fcompose(\n",
    "    get_df,\n",
    "    lambda df: df.T.to_dict().values(),\n",
    "    mapdict(image=lambda data: extract_image(data['filename'])),\n",
    "    mapdict(scaled_image=lambda data: scale_image(data['image'], data['rescale_factor'])),\n",
    "    list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold the images into the ferrite and cementite phase\n",
    "\n",
    "The following reads in the image and uses [Otsu's algorithm](https://en.wikipedia.org/wiki/Otsu%27s_method) to threshold the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Threshold the images into the ferrite and cementite phase\n",
    "threshold_image = fcompose(\n",
    "    PIL.Image.open,\n",
    "    crop_image,\n",
    "    get('upper'),\n",
    "    to_array,\n",
    "    lambda data: data > skimage.filters.threshold_otsu(data)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove White Specs\n",
    "\n",
    "One aspect of cleaning up the noise is to remove the small white specs that occur in the image. According to domain experts, these are not real and are probably caused by the thresholding or image noise. The function `skimage.morphology.remove_small_holes` does that. It removes islands of 0s in a matrix of 1s. We need to remove 1s in a matrix of 1s so we use the not operator, `~`, on both ends of the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove white specs\n",
    "def f_min_size(scale_microns, scale_pixels, island_size=0.2):\n",
    "    return (island_size * scale_pixels / scale_microns)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Closing to Reveal The Pearlite Phase\n",
    "\n",
    "The next part of the analysis reveals the pearlite phase by using a [binary closing](http://homepages.inf.ed.ac.uk/rbf/HIPR2/close.htm), a dilation followed by erosion. This removes the long ferrite spacing in the pearlite. We're using [`skimage.morphology.closing`](http://tonysyu.github.io/scikit-image/api/skimage.morphology.html#skimage.morphology.closing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Binary closing to reveal the Pearlite Phase\n",
    "closing = curry(flip(skimage.morphology.closing))\n",
    "remove_small_holes = curry(skimage.morphology.remove_small_holes)\n",
    "\n",
    "reveal_pearlite = fcompose(\n",
    "    closing(skimage.morphology.square(5)),\n",
    "    remove_small_holes(min_size=1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volume Fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Volume function\n",
    "frac1 = lambda image: float(image.sum()) / image.size\n",
    "frac0 = lambda image: 1 - frac1(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def threshold(filename):\n",
    "\n",
    "    result = dict(filename=filename,\n",
    "                threshold_image=threshold_image(filename),\n",
    "                **extract_metadata(filename))\n",
    "    return result\n",
    "\n",
    "def min_size(data):\n",
    "    data['min_size'] = f_min_size(data['scale_microns'], data['scale_pixels'])\n",
    "    return data\n",
    "\n",
    "def clean(data):\n",
    "    data['clean_image'] = ~remove_small_holes(~data['threshold_image'], data['min_size'])\n",
    "    # print(data['clean_image'])\n",
    "    return data\n",
    "\n",
    "def reveal(data):\n",
    "    data['pearlite_image'] = reveal_pearlite(data['clean_image'])\n",
    "    # print(data['pearlite_image'])\n",
    "    return data\n",
    "\n",
    "def pearlite(data):\n",
    "    data['pearlite_fraction'] = frac1(data['pearlite_image'])\n",
    "    return data\n",
    "\n",
    "def ferrite(data):\n",
    "    data['ferrite_fraction'] = frac0(data['clean_image'])\n",
    "    return data\n",
    "\n",
    "def cemmentite(data):\n",
    "    data['cemmentite_fraction'] = frac1(data['clean_image'])\n",
    "    return data\n",
    "\n",
    "def save(data):\n",
    "    clean_name = data['filename'].split(\"/\")[-1].split(\".\")[0]\n",
    "    file_path = \"{0}.json\".format(clean_name)\n",
    "    filtered_data = {}\n",
    "    filtered_data['filename'] = clean_name\n",
    "    filtered_data['pearlite_fraction'] = data['pearlite_fraction']\n",
    "    filtered_data['ferrite_fraction'] = data['ferrite_fraction']\n",
    "    filtered_data['cemmentite_fraction'] = data['cemmentite_fraction']\n",
    "    with open(file_path, \"w\") as save_file:\n",
    "        save_file.write(json.dumps(filtered_data, sort_keys=True, indent=4, separators=(',', ': ')))\n",
    "\n",
    "def finalize(saves):\n",
    "    print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study/data/1045_Steel_Nital-etch-1.tif\n",
      "study/data/1045_Steel_Nital-etch-2.tif\n",
      "study/data/1045_Steel_Nital-etch-3.tif\n",
      "study/data/1045_Steel_Nital-etch-4.tif\n",
      "study/data/1045_Steel_Nital-etch-5.tif\n",
      "study/data/1045_Steel_Nital-etch-6.tif\n",
      "study/data/1045_Steel_Nital-etch-7.tif\n",
      "study/data/20150911_1045_Nital_etch-1.tif\n",
      "study/data/20150911_1045_Nital_etch-2.tif\n",
      "[#################################       ] | 84% Completed |  1.8sdone.\n",
      "[########################################] | 100% Completed |  1.9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: table;\"><div style=\"display: table-row;\"><div style=\"display: table-cell;\"><b title=\"bokeh.models.layouts.Column\">Column</b>(</div><div style=\"display: table-cell;\">id&nbsp;=&nbsp;'6e2ff4c2-2b9b-4d73-8a18-bcb6f0500492', <span id=\"a41f0661-4417-45ed-95f4-283c6cbf00aa\" style=\"cursor: pointer;\">&hellip;)</span></div></div><div class=\"ff0150f4-bc5b-44d0-8bcc-3850c205411f\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">children&nbsp;=&nbsp;[ToolbarBox(id='56b40c1c-5b87-46ae-8557-0d1f50b74d97', ...), Column(id='abb39c4c-1203-4a76-8199-139203fa589b', ...)],</div></div><div class=\"ff0150f4-bc5b-44d0-8bcc-3850c205411f\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">css_classes&nbsp;=&nbsp;None,</div></div><div class=\"ff0150f4-bc5b-44d0-8bcc-3850c205411f\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">disabled&nbsp;=&nbsp;False,</div></div><div class=\"ff0150f4-bc5b-44d0-8bcc-3850c205411f\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">height&nbsp;=&nbsp;None,</div></div><div class=\"ff0150f4-bc5b-44d0-8bcc-3850c205411f\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_event_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"ff0150f4-bc5b-44d0-8bcc-3850c205411f\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_property_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"ff0150f4-bc5b-44d0-8bcc-3850c205411f\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">name&nbsp;=&nbsp;None,</div></div><div class=\"ff0150f4-bc5b-44d0-8bcc-3850c205411f\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">sizing_mode&nbsp;=&nbsp;'fixed',</div></div><div class=\"ff0150f4-bc5b-44d0-8bcc-3850c205411f\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">subscribed_events&nbsp;=&nbsp;[],</div></div><div class=\"ff0150f4-bc5b-44d0-8bcc-3850c205411f\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">tags&nbsp;=&nbsp;[],</div></div><div class=\"ff0150f4-bc5b-44d0-8bcc-3850c205411f\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">width&nbsp;=&nbsp;None)</div></div></div>\n",
       "<script>\n",
       "(function() {\n",
       "  var expanded = false;\n",
       "  var ellipsis = document.getElementById(\"a41f0661-4417-45ed-95f4-283c6cbf00aa\");\n",
       "  ellipsis.addEventListener(\"click\", function() {\n",
       "    var rows = document.getElementsByClassName(\"ff0150f4-bc5b-44d0-8bcc-3850c205411f\");\n",
       "    for (var i = 0; i < rows.length; i++) {\n",
       "      var el = rows[i];\n",
       "      el.style.display = expanded ? \"none\" : \"table-row\";\n",
       "    }\n",
       "    ellipsis.innerHTML = expanded ? \"&hellip;)\" : \"&lsaquo;&lsaquo;&lsaquo;\";\n",
       "    expanded = !expanded;\n",
       "  });\n",
       "})();\n",
       "</script>\n"
      ],
      "text/plain": [
       "Column(id='6e2ff4c2-2b9b-4d73-8a18-bcb6f0500492', ...)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsk = {}\n",
    "files = sorted(glob.glob(\"study/data/*.tif\"))\n",
    "final_saves = []\n",
    "for filename in files:\n",
    "    print(filename)\n",
    "    filename_cleaned = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    dsk['threshold-{0}'.format(filename_cleaned)] = (threshold, filename)\n",
    "    dsk['min_size-{0}'.format(filename_cleaned)] = (min_size, 'threshold-{0}'.format(filename_cleaned))\n",
    "    dsk['clean-{0}'.format(filename_cleaned)] = (clean, 'min_size-{0}'.format(filename_cleaned))\n",
    "    dsk['reveal-{0}'.format(filename_cleaned)] = (reveal, 'clean-{0}'.format(filename_cleaned))\n",
    "    dsk['pearlite-{0}'.format(filename_cleaned)] = (pearlite, 'reveal-{0}'.format(filename_cleaned))\n",
    "    dsk['ferrite-{0}'.format(filename_cleaned)] = (ferrite, 'pearlite-{0}'.format(filename_cleaned))\n",
    "    dsk['cemmentite-{0}'.format(filename_cleaned)] = (cemmentite, 'ferrite-{0}'.format(filename_cleaned))\n",
    "    dsk['save-{0}'.format(filename_cleaned)] = (save, 'cemmentite-{0}'.format(filename_cleaned))\n",
    "    final_saves.append('save-{0}'.format(filename_cleaned))\n",
    "dsk['finalize'] = (finalize, final_saves)\n",
    "\n",
    "dot_graph(dsk)\n",
    "\n",
    "with ResourceProfiler(0.25) as rprof, Profiler() as prof, CacheProfiler() as cprof, ProgressBar():\n",
    "    dak_get(dsk, 'finalize')\n",
    "\n",
    "visualize([prof, rprof, cprof])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
